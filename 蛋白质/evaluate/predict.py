# predict.py

import pandas as pd
import numpy as np
import argparse
import os
import joblib

# ä»å…±äº«å·¥å…·æ–‡ä»¶ä¸­å¯¼å…¥å‡½æ•°
from utils import check_device, load_esm2_model, get_protein_embeddings_batch


def load_prediction_data(csv_path):
    """ä»CSVæ–‡ä»¶ä¸­åŠ è½½å¾…é¢„æµ‹çš„æ•°æ®ã€‚"""
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"âŒ é”™è¯¯: å¾…é¢„æµ‹æ–‡ä»¶ '{csv_path}' æœªæ‰¾åˆ°ã€‚")

    print(f"ä» {csv_path} åŠ è½½å¾…é¢„æµ‹åºåˆ—...")
    df = pd.read_csv(csv_path)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")
    return df


def load_scoring_model(model_path):
    """åŠ è½½ä¹‹å‰è®­ç»ƒå¥½çš„æ‰“åˆ†æ¨¡å‹ã€‚"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ '{model_path}' æœªæ‰¾åˆ°ã€‚è¯·å…ˆè¿è¡Œ train.py è¿›è¡Œè®­ç»ƒã€‚")

    print(f"æ­£åœ¨ä» {model_path} åŠ è½½æ‰“åˆ†æ¨¡å‹...")
    model = joblib.load(model_path)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
    return model


def analyze_and_annotate(df, trained_seq_col, gen_seq_col, original_score_col):
    """
    åˆ†æé¢„æµ‹åˆ†æ•°ï¼Œå¯¹æ»¡è¶³ç‰¹å®šä¼˜åŒ–æ¡ä»¶çš„åºåˆ—è¿›è¡Œæ ‡æ³¨å’Œç»Ÿè®¡ã€‚
    æ¡ä»¶: å¾®è°ƒæ¨¡å‹é¢„æµ‹åˆ† > åŸå§‹æ¨¡å‹é¢„æµ‹åˆ† > åŸå§‹åºåˆ—çœŸå®åˆ†
    """
    print("\n--- æ­£åœ¨è¿›è¡Œä¼˜åŒ–åˆ†æå’Œæ ‡æ³¨ ---")

    # 1. å®šä¹‰ç”¨äºæ¯”è¾ƒçš„åˆ—å
    # è¯·æ³¨æ„ï¼šåˆ—åæ˜¯æ ¹æ®ä¸»å‡½æ•°ä¸­çš„å‘½åè§„åˆ™ 'predicted_score_' + sequence_column_name ç”Ÿæˆçš„
    score_col_trained = f"predicted_score_{trained_seq_col}"
    score_col_gen = f"predicted_score_{gen_seq_col}"

    # 2. æ£€æŸ¥æ‰€æœ‰éœ€è¦çš„åˆ—æ˜¯å¦å­˜åœ¨äºDataFrameä¸­
    required_cols = [score_col_trained, score_col_gen, original_score_col]
    if not all(col in df.columns for col in required_cols):
        missing_cols = [col for col in required_cols if col not in df.columns]
        print(f"âš ï¸ è­¦å‘Š: ç¼ºå°‘è¿›è¡Œåˆ†ææ‰€éœ€çš„åˆ—: {missing_cols}ã€‚æ— æ³•è¿›è¡Œä¼˜åŒ–åˆ†æã€‚")
        print("   è¯·ç¡®ä¿æ‚¨å·²å¯¹ä»¥ä¸‹åºåˆ—åˆ—è¿›è¡Œäº†æ‰“åˆ†ï¼š", [trained_seq_col, gen_seq_col])
        return df, 0  # è¿”å›åŸå§‹DataFrameå’Œ0è®¡æ•°

    # 3. å®šä¹‰å¸ƒå°”æ¡ä»¶
    condition = (df[score_col_trained] > df[score_col_gen]) & \
                (df[score_col_gen] > df[original_score_col])

    # 4. æ ¹æ®æ¡ä»¶åˆ›å»ºæ–°åˆ— 'æ˜¯å¦ä¼˜åŒ–æˆåŠŸ'
    df['æ˜¯å¦ä¼˜åŒ–æˆåŠŸ'] = np.where(condition, 'æ˜¯', 'å¦')

    # 5. ç»Ÿè®¡æˆåŠŸçš„æ•°é‡
    improvement_count = df['æ˜¯å¦ä¼˜åŒ–æˆåŠŸ'].value_counts().get('æ˜¯', 0)

    print(f"åˆ†æå®Œæˆã€‚æ–°åˆ— 'æ˜¯å¦ä¼˜åŒ–æˆåŠŸ' å·²æ·»åŠ ã€‚")
    print(f"ğŸ“ˆ ä¼˜åŒ–æˆåŠŸ (å¾®è°ƒåˆ† > ç”Ÿæˆåˆ† > åŸå§‹åˆ†) çš„åºåˆ—æ•°é‡: {improvement_count}")

    return df, improvement_count


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¯¹æ–°çš„è›‹ç™½è´¨åºåˆ—è¿›è¡Œæ‰“åˆ†ï¼Œå¹¶è¿›è¡Œä¼˜åŒ–åˆ†æã€‚",
        formatter_class=argparse.RawTextHelpFormatter  # ä¿æŒå¸®åŠ©ä¿¡æ¯æ ¼å¼
    )
    parser.add_argument(
        "--csv_path",
        type=str,
        default="./predict_result_3.csv",
        help="åŒ…å«å¾…æ‰“åˆ†è›‹ç™½è´¨åºåˆ—çš„CSVæ–‡ä»¶è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--sequence_columns",
        type=str,
        nargs='+',  # æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå€¼
        required=True,
        help="éœ€è¦è¿›è¡Œæ‰“åˆ†çš„åˆ—ååˆ—è¡¨ï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚\n"
             "ä¾‹å¦‚: --sequence_columns mutated_sequence predicted_sequence_trained predicted_sequence"
    )
    parser.add_argument(
        "--model_input_path",
        type=str,
        default="scoring_model.pth",
        help="é¢„è®­ç»ƒæ‰“åˆ†æ¨¡å‹æƒé‡çš„æ–‡ä»¶è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--output_csv_path",
        type=str,
        default="predicted_scores_with_analysis_3.csv",
        help="ä¿å­˜æ‰“åˆ†å’Œåˆ†æç»“æœçš„CSVæ–‡ä»¶è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--model_name",
        type=str,
        default="esm2_t12_35M_UR50D",
        help="ç”¨äºç”ŸæˆåµŒå…¥å‘é‡çš„ESM-2æ¨¡å‹åç§°ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„æ¨¡å‹ä¸€è‡´ï¼‰ã€‚"
    )
    parser.add_argument(
        "--repr_layer",
        type=int,
        default=12,
        help="ä»ESMæ¨¡å‹çš„å“ªä¸€å±‚æå–è¡¨å¾ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰ã€‚"
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=16,
        help="ç”ŸæˆåµŒå…¥å‘é‡æ—¶çš„æ‰¹æ¬¡å¤§å°ã€‚"
    )

    args = parser.parse_args()

    # 1. åˆå§‹åŒ–å’ŒåŠ è½½
    device = check_device()
    df = load_prediction_data(args.csv_path)
    scoring_model = load_scoring_model(args.model_input_path)
    esm_model, alphabet, batch_converter = load_esm2_model(args.model_name, device)

    # 2. å¾ªç¯ä¸ºæ¯ä¸ªæŒ‡å®šçš„åºåˆ—åˆ—ç”ŸæˆåµŒå…¥å‘é‡å¹¶é¢„æµ‹åˆ†æ•°
    for col in args.sequence_columns:
        print(f"\n--- æ­£åœ¨å¤„ç†åˆ—: '{col}' ---")

        if col not in df.columns:
            print(f"âš ï¸ è­¦å‘Š: æŒ‡å®šçš„åˆ— '{col}' åœ¨CSVæ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚")
            continue

        sequences = df[col].dropna().tolist()
        if not sequences:
            print(f"â„¹ï¸ åˆ— '{col}' ä¸­æ²¡æœ‰æœ‰æ•ˆåºåˆ—ï¼Œè·³è¿‡ã€‚")
            continue

        embeddings = get_protein_embeddings_batch(
            sequences, esm_model, alphabet, batch_converter, device, args.repr_layer, args.batch_size
        )

        predictions = scoring_model.predict(embeddings)
        pred_series = pd.Series(predictions, index=df[col].dropna().index)

        output_col_name = f"predicted_score_{col}"
        df[output_col_name] = pred_series
        df[output_col_name] = df[output_col_name].round(9)
        print(f"âœ… å·²ç”Ÿæˆé¢„æµ‹åˆ†æ•°å¹¶æ·»åŠ åˆ°æ–°åˆ— '{output_col_name}'ã€‚")

    # 3. æ‰§è¡Œåˆ†æå’Œæ ‡æ³¨
    # æ ¹æ®æ‚¨çš„CSVæ–‡ä»¶ï¼Œåˆ—åæ˜¯å›ºå®šçš„
    df_analyzed, count = analyze_and_annotate(
        df=df,
        trained_seq_col="predicted_sequence_trained",
        gen_seq_col="predicted_sequence",
        original_score_col="DMS_score"
    )

    # 4. ä¿å­˜æœ€ç»ˆç»“æœ
    try:
        # è·å–è¾“å‡ºè·¯å¾„çš„ç›®å½•éƒ¨åˆ†
        output_dir = os.path.dirname(args.output_csv_path)

        # åªæœ‰å½“ç›®å½•åä¸ä¸ºç©ºæ—¶ï¼Œæ‰å°è¯•åˆ›å»ºç›®å½•
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"å·²åˆ›å»ºç›®å½•: {output_dir}")
        df_analyzed.to_csv(args.output_csv_path, index=False, float_format='%.9f')
        print(f"\nğŸ‰ æ‰€æœ‰æ‰“åˆ†å’Œåˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {args.output_csv_path}")
        print("\næœ€ç»ˆç»“æœé¢„è§ˆ:")
        # é¢„è§ˆæ—¶æ˜¾ç¤ºå…³é”®åˆ—
        preview_cols = list(args.sequence_columns) + \
                       [f"predicted_score_{col}" for col in args.sequence_columns] + \
                       ['DMS_score', 'æ˜¯å¦ä¼˜åŒ–æˆåŠŸ']
        # ç¡®ä¿é¢„è§ˆçš„åˆ—éƒ½å­˜åœ¨
        preview_cols = [c for c in preview_cols if c in df_analyzed.columns]
        print(df_analyzed[preview_cols].head().to_string())
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœCSVæ—¶å‡ºé”™: {e}")


if __name__ == "__main__":
    main()